The half-day program, co-sponsored with the University of Washington School of Law and the university’s Tech Policy Lab, was the first of four events the White House has planned that will focus on law and policy, as well as the social and economic implications of autonomous machine research.

“These issues of A.I. and machines learning were popping up all over the government, and there was an opportunity to get more coordinated in how we address them,” Dr. Felten said.

After 25 artificial intelligence researchers met in 2009, the group, sponsored by the Association for the Advancement of Artificial Intelligence, reported that there was no imminent danger from a technology that had prompted fears of Hollywood-style weapons and advanced economies that were devoid of human workers.

Leading technologists and scientists have also pondered the possibility that artificial intelligence, like genetic engineering, might soon constitute an existential threat to the human race.

Newsletter Sign Up Continue reading the main story Please verify you're not a robot by clicking the box. Invalid email address. Please re-enter. You must select a newsletter to subscribe to. Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services. Thank you for subscribing. An error has occurred. Please try again later. View all New York Times newsletters.

In recent years, the debate has spread to the broader social impact of autonomous programs that will perform tasks like driving cars and offering medical and financial advice.

One challenge for A.I., according to a number of the researchers who spoke, is that the public perception about the threat of A.I. has largely been shaped by Hollywood.

“Certainly, Hollywood has played a tremendous role with vision like Skynet,” the computer network that turns on humans in the “Terminator” movies, said Oren Etzioni, chief executive of the Allen Institute for Artificial Intelligence, a nonprofit research group funded by the Microsoft co-founder Paul Allen. “It’s pretty much always the case in science fiction that A.I. is this monolithic entity that is scheming to take over.”

He cautioned that attention-getting feats like Google’s AlphaGo program, which defeated a human champion in the board game Go, had plenty of humans behind the machine doing the work.

Advertisement Continue reading the main story

At the same time, despite the consensus about the limits of today’s technology, many of the panelists wrestled with new challenges presented by A.I. systems that were appearing in virtually all walks of life, including services delivered by smartphones and algorithms that guide missiles.

Kate Crawford, a principal researcher at Microsoft Research, called on the industry to add ethics to the professional training of engineers. “We need to start changing the skill set of the people who are going to be the data scientists of the future and the A.I. creators of the future,” she said.

A.I. systems are pervasive, Ms. Crawford said, pointing to a doll like Hello Barbie, which speaks and listens.

“You might think that’s a fantastic toy, that’s really wonderful,” she said. “What you don’t realize is that it is the front to this huge data ingestion machine that is taking all of those statements by that child and then using them for a whole range of purposes.”