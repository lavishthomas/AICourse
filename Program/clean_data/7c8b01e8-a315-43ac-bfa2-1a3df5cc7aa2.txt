Full Site Articles EconLog EconTalk Books Encyclopedia Guides Articles EconLog EconTalk Books Encyclopedia Guides Search The Practitioner's Challenge Arnold Kling * EMAIL CITE COPYRIGHT SHARE CLEAR HIGHLIGHTS I n The End of Theory, Richard Bookstaber has issued a powerful challenge to conventional economic research and analysis. Like me, Bookstaber earned his PhD in economics from MIT several decades ago. And like me, having spent more of his career as a financial practitioner than as an academic, he is highly critical of the mainstream approach to economics that is most closely associated with MIT. What makes The End of Theory unusual among critiques of its genre is that Bookstaber makes a case for an interesting alternative approach, called agent-based modeling (ABM). If I could reduce to a bumper sticker how ABM practitioners differ from mainstream economists, it would read, "Stare at the world, not at your model." Olivier Blanchard, in an article in which he asserted, "The state of macro is good," nonetheless noted, It is not just macro. All of the major fields in economics are inclined to follow strict technical procedures at the expense of realism. In the 1500s, if mapmakers had been similarly inward-looking and rigid, they would have continued to draw maps of the globe that ignored the lands discovered by Columbus and subsequent explorers, insisting that "The state of cartography is good." The haiku of mainstream economics includes seeking closed-form mathematical solutions of constrained optimization problems, examining behavior in the neighborhood of equilibrium, and looking at the real world through the lens of statistical analysis of data that is assumed to come from stable distributions. Bookstaber would relax these rules. The looser approach of ABM would instead try to include every real-world characteristic thought to be important, regardless of how complex it makes the model. With the conventional approach, an economist will try to mathematically derive an interesting result using the simplest model possible. This has the benefit of making it easier to write down a clear representation and to obtain the desired result. However, the drawback of this approach is that in order not to over-complicate the model, it deliberately leaves out factors that are present in the real world. With the conventional approach, economists use deductive mathematics to arrive at closed-form solutions. With ABM, the analyst conducts simulation exercises of models that have no closed-form solutions. With the conventional approach, the economist solves for the equilibrium and examines behavior in the neighborhood of that equilibrium. With ABM, analysts look at dynamics starting from a variety of initial conditions. They do not presume that equilibrium is the most likely state, or even that there is an equilibrium. With the conventional approach, economists treat agents as solving constrained optimization problems. When they discover that real decision-makers use heuristics, economists deride those heuristics as irrational, and they proceed to show how heuristics lead to departures from optimality. With ABM, heuristics are considered a rational response to a radically uncertain world. Simulations should incorporate realistic decision-making by agents operating in the context of systems that are too complex for anyone to understand. Conventional economists observe real-world behavior as it manifests itself indirectly in data. They apply statistical techniques that assume what we observe today tells us what we will observe tomorrow. ABM allows for the fact that as humans interact with their environment and with one another, behavior changes, potentially rendering past data irrelevant. In order to avoid relying on ephemeral statistical findings, one has to examine more directly the decision-makers and their thought processes. Bookstaber says that ABM is needed instead of conventional economics because of "emergent phenomena, [non-]ergodicity, radical uncertainty, and computational irreducibility." (Bookstaber, page 12) Each of these features of the world make it difficult for simple, fixed models to be robust. Bookstaber writes, Some emergent phenomena, such as language and cultural norms, evolve slowly. Other emergent phenomena, such as traffic jams or stampedes, appear suddenly. Economists cannot rely on mere statistical analysis of data, because of non-ergodicity. "The alternative assumption, that the future has aspects that are not foreseeable today, goes by the name of 'radical uncertainty.' But we might just call it the human condition." In conventional economics, people are assumed to know, now and for the indefinite future, the entire range of possibilities, and the likelihood of each. The alternative assumption, that the future has aspects that are not foreseeable today, goes by the name of "radical uncertainty." But we might just call it the human condition. Bookstaber writes that radical uncertainty "leads the world to go in directions we had never imagined... The world could be changing right now in ways that will blindside you down the road." (page 18). By computational irreducibility, Bookstaber means that much of economic behavior is too complex to be studied using simple models. "The world cannot be solved; it has to be lived." (page 18) These features mean that, Bookstaber argues for incorporating George Soros' principle of reflexivity. Making economic decisions involves interpreting the environment (the cognitive function) and changing the environment (the manipulative function). People are continually learning and continually changing. This is an important source of radical uncertainty that is not present in most branches of natural science. These methodological differences can be illustrated with a number of specific cases. Note that these are my examples, not Bookstaber's. First, consider the problem of designing contracts to compensate employees. The owner of the firm wants to get the most productive work from the employees while offering the least compensation. The employees want to obtain the most compensation for the least effort. If the contract offers a well-constructed set of bonuses and incentives, the firm will operate efficiently and workers will be paid appropriately. If the contract is carelessly crafted, then employees will game the system. The firm will earn less, and this likely means that workers, too, will earn less than with a well-designed contract. There is an extensive mainstream literature on this topic, known as the principal-agent problem. Much of it revolves around the concept of an "incentive-compatible contract," which means a contract that permanently and optimally solves the problem. However, from the perspective of ABM, there is no such thing as an incentive-compatible contract. Instead, there is radical uncertainty and reflexivity. No one has enough information to design a "perfect" compensation system. Even if a system appears to be perfect based on the situation that prevails at the moment, no one knows how employees in the future might discover new ways to game the system. No one knows how changes in the business environment will degrade the effectiveness of the contract. Owners and employees continually learn and adapt. Optimal strategies are elusive, and instead agents use heuristics that they hope are robust. Owners delegate to managers the task of "performance evaluation," and they allow managers to use this process to exercise some discretion in compensation. Real-world businesses revise their compensation plans periodically, because the effectiveness of any plan tends to degrade over time. Workers attempt to benchmark their compensation against that of peers both within and outside the firm. A second example is the decision to buy a home. An economist's calculation might compare the benefit of not paying rent with the interest cost. Note that the economist sees interest cost regardless of whether it appears in a mortgage or is merely the interest foregone on assets sacrificed to make a down payment. The economist would assume that households would use this calculation in making their decisions. Instead, many consumers use a monthly payment heuristic. If the monthly mortgage payment for buying a house is in the ballpark of the rent that they pay, then they are inclined to buy. If the monthly mortgage payment is considerably higher, then they do not buy. In an environment where inflation is high and mortgage rates are also high, the monthly-payment heuristic tends to limit the demand for home ownership to families that are prepared to make a large down payment. Without a large down payment, a sizable mortgage at a high nominal interest rate imposes a mortgage payment far higher than the rent on an equivalent dwelling. In an environment where inflation is low and mortgage rates are also low, the monthly-payment heuristic can be favorable to buying even for families that are not prepared to make a large down payment. Thus, in the low-inflation environment that we have experienced thus far in the 21st century, home purchase became attractive to more families, and in particular to more families without the wherewithal to make a large down payment. Up until around 2007, the institutional response of both private industry and public policy was to try to accommodate this demand with looser credit standards for mortgages. This emergent phenomenon is not something that one would have predicted from a model based on economic calculation. Understanding it requires taking into account the heuristics that people use. As another example, consider the analysis of asset price volatility for which Robert Shiller was awarded a Nobel prize. To oversimplify a bit, suppose that you take the average ratio of house prices to rents over the past 100 years. If you plot the behavior of this ratio over time, it will go through alternating cycles above and below its mean. One might conclude that the price/rent ratio is "mean-reverting," meaning that if the historical average is 12 and today it is 18, then it is bound to go down, and if today it is 6 then it is bound to go up. This suggests that you can identify relatively easily situations in which assets are overpriced or underpriced. And yet, Shiller's market "calls," like those of other forecasters, have had a mixed track record. Shiller's analysis is a classic example of finding statistical patterns that may not obtain in the future. As historical analysis, Shiller's calculations will work regardless of whether the process is ergodic. But only if it is ergodic will the extrapolation into the future be reliable. Even a process as non-ergodic as a random walk will generate a history that appears to be mean-reverting. But whether it reverts going forward would be a fifty-fifty proposition. In a non-ergodic world, past performance does not guarantee future returns. There is the chance that this time really is different. Shiller was on more solid ground, in my view, when he surveyed home buyers during the boom and found that they were extrapolating into the future the high rates of house price appreciation that they had recently observed. In the later stages of the boom, in 2005-2006, an unusually large share of mortgage loans went for purchases of non-owner-occupied housing. In other words, "house flipping" and other forms of speculation were increasingly important. The belief that house prices were rising motivated these sorts of actions, which in turn fed the boom in house prices, which in turn reinforced the belief that home prices would increase going forward. This dynamic interaction between beliefs and actions illustrates the principle of reflexivity. Bookstaber stresses the advantage of ABM, or what I call staring at the world, for understanding the financial crisis of 2008. Like Gary Gorton and Andrew Metrick, Bookstaber views the events that took place in securities markets as analogous to a bank run. Bookstaber notes that many modern financial transactions, including repurchase agreements and derivative contracts, require one party to put up small amounts of low-risk assets as good-faith collateral. As concerns developed about the risk of mortgage securities, this adversely affected their assessed value as collateral. Bookstaber writes, Suppose that you were an investment bank financing your holdings of mortgage securities using a repurchase agreement (the repo loan market, as it is called). During the crisis, the lending institution might mark down the value of those securities, and that forces you to borrow more money than was required when the assessed value was higher. I would cite the problems at AIG insurance as a different, but related, example. There, the markdown of mortgage security values frightened the institutions to which AIG had sold credit default swaps, which are a form of insurance against bond defaults, to investment banks like Goldman Sachs. Concerned that AIG might soon have to pay on those contracts, the buyers of credit default swaps demanded that AIG post collateral. This is equivalent to homeowners with flood insurance, seeing the river near their homes starting to rise, demanding that the insurance company put safe securities into an escrow account, even though the water has not yet reached the house. With safe securities in short supply in the late summer of 2008, AIG could not meet these "collateral calls," and had to be bailed out. This was true even though most of the bonds never defaulted (the water never reached the home). In my view, had policy makers understood what was happening at the time, they could have interrupted the crisis by pressuring institutions to be less aggressive in their collateral calls and in their asset markdowns in the repo market. As the crisis was unfolding, I termed this the "stern sheriff" model, because I thought of it as a sheriff coming into a gambling hall where players are arguing and fighting and telling the players that they need to cool down and wait a while for the casino to sort out whose chips are whose. But if policy makers had only an imperfect grasp of what was happening, then economists had no understanding at all. Their simple haiku-like models had no concept of the dynamics of repurchase agreements or credit default swaps. Standard models had almost no role at all for financial institutions as distinct agents whose behavior affects the economy. By staring at the world instead of at a model, Bookstaber is able to explain the financial turmoil that erupted in 2008. However, neither Bookstaber, policy makers, nor conventional economists have explained in a convincing and satisfying way the deep recession that followed. It seems to me that the dislocations in financial markets need not have disrupted the rest of the economy. Moreover, most of the suffering in the rest of the economy took place long after the symptoms of stress on Wall Street had receded. For more on these topics, see the EconTalk podcast episodes Leamer on the State of Econometrics and James Heckman on Facts, Evidence, and the State of Econometrics. See also "Present at the Destruction," by Arnold Kling, Library of Economics and Liberty, April 3, 2017. These issues are taken up in Economics for Independent Thinkers, by Daniel Nevins, another former practitioner of quantitative finance. He argues that recessions are partly caused by the excesses of earlier expansions, reflecting credit cycles, human nature, and the business environment. He draws parallels between the 1920s expansion and the expansion that preceded the 2008 financial crisis: commercial construction was the housing bubble of the 1920s.

securities loans were the subprime of the 1920s.

installment loans were the option-ARM rate resets of the 1920s.

securities affiliates were the structured investment vehicles of the 1920s.

America was the Germany or Japan of 1920s exporters. Like Bookstaber, Nevins has harsh things to say about mainstream economists. Mainstream economics certainly has no role for the sectoral excesses that Nevins sees as central to economic fluctuations. In most models, sectoral excesses are ruled out by construction. Bookstaber writes, I strongly agree. I view increases in unemployment as a result of patterns of specialization and trade breaking down faster than entrepreneurs can discover new sustainable patterns. Trying to model the economy without specialization is an example of economists attempting Hamlet without the prince. The theory of patterns of sustainable specialization and trade is difficult to express in models meeting the rigid requirements of mainstream Haiku. It is more plausibly expressed using the sort of agent-based modeling advocated by Bookstaber. 1. Richard Bookstaber, The End of Theory: Financial Crises, the Failure of Economics, and the Sweep of Human Interaction. Princeton University Press, 2017. 2. Olivier Blanchard, "The State of Macro," Annual Reviews of Economics 1:209-228, September 2009. 3. Gary B. Gorton and Andrew Metrick, "Securitized Banking and the Run on Repo," Yale Working Paper 2009 (revised 2013). 4. Daniel Nevins, Economics for Independent Thinkers. 5. See Arnold Kling, Specialization and Trade and EconTalk, Kling on Specialization and Trade. Crisis of Abundance: Rethinking How We Pay for Health Care; Invisible Wealth: The Hidden Story of How Markets Work; Unchecked and Unbalanced: How the Discrepancy Between Knowledge and Power Caused the Financial Crisis and Threatens Democracy; and



For more articles by Arnold Kling, see the



* Arnold Kling has a Ph.D. in economics from the Massachusetts Institute of Technology. He is the author of several books, including; and Specialization and Trade: A Re-introduction to Economics . He contributed to EconLog from January 2003 through August 2012.For more articles by Arnold Kling, see the Archive Return to top