THERE IS SOMETHING familiar about fears that new machines will take everyone’s jobs, benefiting only a select few and upending society. Such concerns sparked furious arguments two centuries ago as industrialisation took hold in Britain. People at the time did not talk of an “industrial revolution” but of the “machinery question”. First posed by the economist David Ricardo in 1821, it concerned the “influence of machinery on the interests of the different classes of society”, and in particular the “opinion entertained by the labouring class, that the employment of machinery is frequently detrimental to their interests”. Thomas Carlyle, writing in 1839, railed against the “demon of mechanism” whose disruptive power was guilty of “oversetting whole multitudes of workmen”.

Today the machinery question is back with a vengeance, in a new guise. Technologists, economists and philosophers are now debating the implications of artificial intelligence (AI), a fast-moving technology that enables machines to perform tasks that could previously be done only by humans. Its impact could be profound. It threatens workers whose jobs had seemed impossible to automate, from radiologists to legal clerks. A widely cited study by Carl Benedikt Frey and Michael Osborne of Oxford University, published in 2013, found that 47% of jobs in America were at high risk of being “substituted by computer capital” soon. More recently Bank of America Merrill Lynch predicted that by 2025 the “annual creative disruption impact” from AI could amount to $14 trillion-33 trillion, including a $9 trillion reduction in employment costs thanks to AI-enabled automation of knowledge work; cost reductions of $8 trillion in manufacturing and health care; and $2 trillion in efficiency gains from the deployment of self-driving cars and drones. The McKinsey Global Institute, a think-tank, says AI is contributing to a transformation of society “happening ten times faster and at 300 times the scale, or roughly 3,000 times the impact” of the Industrial Revolution.

Just as people did two centuries ago, many fear that machines will make millions of workers redundant, causing inequality and unrest. Martin Ford, the author of two bestselling books on the dangers of automation, worries that middle-class jobs will vanish, economic mobility will cease and a wealthy plutocracy could “shut itself away in gated communities or in elite cities, perhaps guarded by autonomous military robots and drones”. Others fear that AI poses an existential threat to humanity, because superintelligent computers might not share mankind’s goals and could turn on their creators. Such concerns have been expressed, among others, by Stephen Hawking, a physicist, and more surprisingly by Elon Musk, a billionaire technology entrepreneur who founded SpaceX, a rocket company, and Tesla, a maker of electric cars. Echoing Carlyle, Mr Musk warns that “with artificial intelligence, we’re summoning the demon.” His Tesla cars use the latest AI technology to drive themselves, but Mr Musk frets about a future AI overlord becoming too powerful for humans to control. “It’s fine if you’ve got Marcus Aurelius as the emperor, but not so good if you have Caligula,” he says.

It’s all Go

Such concerns have been prompted by astonishing recent progress in AI, a field long notorious for its failure to deliver on its promises. “In the past couple of years it’s just completely exploded,” says Demis Hassabis, the boss and co-founder of DeepMind, an AI startup bought by Google in 2014 for $400m. Earlier this year his firm’s AlphaGo system defeated Lee Sedol, one of the world’s best players of Go, a board game so complex that computers had not been expected to master it for another decade at least. “I was a sceptic for a long time, but the progress now is real. The results are real. It works,” says Marc Andreessen of Andreessen Horowitz, a Silicon Valley venture-capital firm.

In particular, an AI technique called “deep learning”, which allows systems to learn and improve by crunching lots of examples rather than being explicitly programmed, is already being used to power internet search engines, block spam e-mails, suggest e-mail replies, translate web pages, recognise voice commands, detect credit-card fraud and steer self-driving cars. “This is a big deal,” says Jen-Hsun Huang, chief executive of NVIDIA, a firm whose chips power many AI systems. “Instead of people writing software, we have data writing software.”

Where some see danger, others see opportunity. Investors are piling into the field. Technology giants are buying AI startups and competing to attract the best researchers from academia. In 2015 a record $8.5 billion was spent on AI companies, nearly four times as much as in 2010, according to Quid, a data-analysis company. The number of investment rounds in AI companies in 2015 was 16% up on the year before, when for the technology sector as a whole it declined by 3%, says Nathan Benaich of Playfair Capital, a fund that has 25% of its portfolio invested in AI. “It’s the Uber for X” has given way to “It’s X plus AI” as the default business model for startups. Google, Facebook, IBM, Amazon and Microsoft are trying to establish ecosystems around AI services provided in the cloud. “This technology will be applied in pretty much every industry out there that has any kind of data—anything from genes to images to language,” says Richard Socher, founder of MetaMind, an AI startup recently acquired by Salesforce, a cloud-computing giant. “AI will be everywhere.”

What will that mean? This special report will examine the rise of this new technology, explore its potential impact on jobs, education and policy, and consider its ethical and regulatory implications. Along the way it will consider the lessons that can be learned from the original response to the machinery question. AI excites fear and enthusiasm in equal measure, and raises a lot of questions. Yet it is worth remembering that many of those questions have been asked, and answered, before.

Read on: How the technology works >>