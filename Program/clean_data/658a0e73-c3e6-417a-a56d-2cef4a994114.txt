But that’s not to say that there hasn’t been progress made. Right now, LeCun is excited about work on a “memory” network that can be integrated into present convolutional neural networks, giving them the ability to retain information. He likens the new mode of memory retention to short term and long term memory in the brain, governed by the hippocampus and cerebral cortex respectively. (LeCun actually detests CNNs being compared to brains, instead preferring a model of a black box with 500 million knobs.)

The memory module allows researchers to tell the network a story, and then have it answer questions about the story later.

For the story, they used J.R.R. Tolkein’s Lord of the Rings Well, not the entire book, but short summaries of major plot points. (“Bilbo took the ring.”) When asked questions about where the ring was at certain points in the story, the AI would be able to answer in short, correct answers. This means it “understands” relationships between objects and time, according to CTO Mike Schroepfer, who stressed this technology’s ability to help Facebook show you what you want to see with higher accuracy.

“By building systems that understand the context of the world, understand what it is you want, we can help you there,” Schroepfer said at a developer presentation in March. ”We can build systems that make sure all of us spend time on the things we care about.”

The FAIR team is developing this context around a project called “Embed the World.” To help machines better understand reality, the FAIR team is teaching them to represent the relationships between everything in vectors: images, posts, comments, photos, and video. The neural network is creating an intricate web of content that groups like pieces of media, and distances different ones. There’s a helpful video to visualize this:

Video of Embed The World

With this system, LeCun says that we can start to “replace reasoning with algebra.” And it’s incredibly powerful. The artificial neural networks developed in the Embed the World project can link two photos that were taken in the same location based on visual similarities in the photos, but also figure out if text describes the scene. It’s recreating a virtual memory of reality, and clustering it in the context of other places and events. It can even “virtually represent a person,” based on their previous likes, interests, and digital experiences. This is somewhat experimental, but has great implications for Facebook’s News Feed and is used in a limited way to track hashtags.

"If we have an idea that actually works, within a month it can be in front of 1.5 billion people."

There’s a lot of talk about long-term goals, but small victories along the way have made Facebook incrementally smarter. In June 2014, they published an article titled “DeepFace: Closing the Gap to Human-Level Performance in Face Verification,” which claimed more than 97 percent accuracy in recognizing faces. LeCun says that he’s confident Facebook’s facial recognition is the best in the world, and that it’s a key difference between Facebook and academic research institutions. Now, DeepFace is driving force behind Facebook’s automatic photo tagging.

“If we have an idea that actually works, within a month it can be in front of 1.5 billion people,” LeCun said, “Lets keep our eyes focused on the horizon, where our long-term goal is, but on the way there are a lot of things that we’re going to build that are going to have applications in the short term.”

Rob Fergus, right, stands among FAIR researchers at Facebook's New York City office. Fergus' work is concerned with the visual element of artificial intelligence. Dave Gershgorn/ Popular Science

Rob Fergus, a veteran of NYU and MIT’s Computer Science and Artificial Intelligence Lab, leads the AI research team concerned with vision. His team’s work that can already been seen in the automatic tagging of photos, but Fergus says the next step is video. Lots of video is “lost” in the noise because of a lack of metadata, or it’s not accompanied by any descriptive text. AI would “watch” the video, and be able to classify video arbitrarily.

This has major implications for stopping content Facebook doesn’t want from getting onto their servers—like pornography, copyrighted content, or anything else that violates their terms of service. It also could identify news events, and curate different types of video category. Facebook has traditionally farmed these tasks out to contracted companies, so this could potentially play a role in mitigating costs.

In current tests, the AI shows promise. When shown a video of sports being played, like hockey, basketball or table tennis, it can correctly identify the sport. It can tell baseball from softball, rafting from kayaking, and basketball from street ball.