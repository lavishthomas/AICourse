{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignement Details\n",
    "Name        : **Lavish Thomas** <br> \n",
    "Student ID  : **L00150445** <br>\n",
    "Course      : MSc in Big Data Analytics and Artificial Intelligence <br>\n",
    "Module      : Artificial Intelligence 2 <br>\n",
    "File used   : Quara.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataframe = pd.read_csv(\"quora_questions.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808578"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808577"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_series = pd.notnull(raw_dataframe[\"question\"])\n",
    "data_frame = raw_dataframe[bool_series]\n",
    "len(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question\n",
       "0  What is the step by step guide to invest in sh...\n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
       "2  How can I increase the speed of my internet co...\n",
       "3  Why am I mentally very lonely? How can I solve...\n",
       "4  Which one dissolve in water quikly sugar, salt..."
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame[\"question\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_df is between 0-1 or an INT\n",
    "count_vectorizer = CountVectorizer(max_df=0.90, min_df=4, stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix = count_vectorizer.fit_transform(data_frame[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<808577x34025 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4001624 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# n_components = no of topics. This for now is trial-and-error\n",
    "# I'm starting with 10 topics that could be in this group of texts\n",
    "lda = LatentDirichletAllocation(n_components=10, random_state=1)\n",
    "\n",
    "lda.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics - log likelihood - higher score = better\n",
    "print(\"Log likelihood : \", lda.score(doc_term_matrix))\n",
    "# Perplexity - lower = better. \n",
    "# = exp(-1 * log likelihood per word)\n",
    "print(\"Perplexity: \", lda.perplexity(doc_term_matrix))\n",
    "len(count_vectorizer.get_feature_names())\n",
    "count_vectorizer.get_feature_names()[1500]\n",
    "lda.components_.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "probability_list = []\n",
    "\n",
    "top_number = 20\n",
    "topic_count = 0\n",
    "\n",
    "for probability_number in lda.components_:\n",
    "    text_message = f\"Top words for topic {topic_count} are : \"\n",
    "    print(text_message)\n",
    "    for number in probability_number.argsort()[-top_number:]:\n",
    "        print([count_vectorizer.get_feature_names()[number]], end=\"\")\n",
    "        probability_list.append(number)\n",
    "    print(\"\\n\")\n",
    "    topic_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Defien the params that we want to use\n",
    "search_params = {\"n_components\": [5, 7, 10, 12, 15], \"learning_decay\": [.5, .7, .9]}\n",
    "\n",
    "# Init the model\n",
    "lda_comparison = LatentDirichletAllocation()\n",
    "\n",
    "# Init Grid Search Class\n",
    "lda_comparison = GridSearchCV(lda_comparison, param_grid=search_params)\n",
    "\n",
    "# Run the grid search\n",
    "lda_comparison.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model which gives the highest score\n",
    "best_lda_model = lda_comparisoncomparisoncomparisoncomparison.best_estimator_\n",
    "\n",
    "# Model parameters is used to store a list of params settings for allprint \n",
    "# parameters candidatelda_comparisonint(\"Best model params: \", lda_comparison.beprintarams_)\n",
    "\n",
    "# Best log likelihoodlda_comparisonprint(\"Best log likelihood score\", lda_comparison.best_score_)\n",
    "\n",
    "# Best perplexity\n",
    "print(\"Model perplexity : \", best_lda_model.perplexity(doc_term_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
