{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Details\n",
    "Name        : **Lavish Thomas** <br> \n",
    "Student ID  : **L00150445** <br>\n",
    "Course      : MSc in Big Data Analytics and Artificial Intelligence <br>\n",
    "Module      : Artificial Intelligence 2 <br> \n",
    "Assignment  : NLP CA 2 <br>\n",
    "File used   : **quora_questions.csv**\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries Used:\n",
    "This sections explains varies libraries used in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy\n",
    "NumPy is the fundamental package for scientific computing with Python for efficient multi-dimensional container of generic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit-learn\n",
    "Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection and evaluation, and many other utilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pandas\n",
    "Pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer \n",
    "CountVectorizer is used to split up the reviews into a list of words(a spare matrix with count of each word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Dirichlet Allocation\n",
    "The latent Dirichlet allocation (LDA) is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search\n",
    "Hyper-parameters are parameters that are not directly learnt within estimators. Grid Search is used to find optimal hypermeters for the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultinomialNB\n",
    "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Test split\n",
    "Split arrays or matrices into random train and test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "Metrics module implements several loss, score, and utility functions to measure classification performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the CSV file with questions\n",
    "The files are read and loaded into a datframe using the pandas inbuild function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataframe = pd.read_csv(\"quora_questions.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Size of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the dataset is 808578\n"
     ]
    }
   ],
   "source": [
    "print (\"The size of the dataset is \" + str(len(raw_dataframe)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question\n",
       "0  What is the step by step guide to invest in sh...\n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
       "2  How can I increase the speed of my internet co...\n",
       "3  Why am I mentally very lonely? How can I solve...\n",
       "4  Which one dissolve in water quikly sugar, salt..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataframe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting the null rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_series = pd.notnull(raw_dataframe[\"question\"])\n",
    "not_null_data_frame = raw_dataframe[bool_series]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling the data set \n",
    "Randomly 200000 questions from the given dataset is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = not_null_data_frame.sample(n = 200000, random_state = 101).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Cross checking the size.\n",
    "len(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Method to find separation of slits using fresn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How do I read and find my YouTube comments?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What can make Physics easy to learn?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question\n",
       "2   How can I increase the speed of my internet co...\n",
       "3   Why am I mentally very lonely? How can I solve...\n",
       "10  Method to find separation of slits using fresn...\n",
       "11        How do I read and find my YouTube comments?\n",
       "12               What can make Physics easy to learn?"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Sample dataset\n",
    "data_frame.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making sure there is no null lines\n",
    "data_frame[\"question\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aim:\n",
    "\n",
    "To evaluate the unsupervised machine learning methods for text classification, which is suitable for the provided dataset named quora questions, which is extracted from the popular Q&A platform on the internet \"Quora\". \n",
    "\n",
    "#### Method:\n",
    "Two unsupervised machine learning methods are available in the scikit-learn library for text classification. <br>\n",
    "1)\tLatentDirichletAllocation (LDA) <br>\n",
    "2)\tNon-Negative Matrix Factorisation(NMF) <br>\n",
    "\n",
    "In this library, LDA provides the log-likelihood and proximity score to evaluate the hyperparameter setting for a model. But in the current released version of the library, the NMF does not have a scoring mechanism. Hence, the LDA method will be employed in this project.\n",
    "\n",
    "#### Expected output:\n",
    "The expected artefacts of this question is a dataset which will be categorised under several topics. The topics names should be selected using the probability of words in each topic based on empirical knowledge.\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of Document matrix\n",
    "\n",
    "This creates a sparse matrix which has the occurrence count of each word for each row of the data frame.<br> <br>\n",
    "**CountVectorizer** is used with options: <br> \n",
    "**max_df=0.9** which identify the highly repeated words as stop words and  <br> \n",
    "**min_df=4** which identifies the scarcely occuring words as stop words too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_df is between 0-1 or an INT\n",
    "count_vectorizer = CountVectorizer(max_df=0.90, min_df=4, stop_words=\"english\")\n",
    "doc_term_matrix = count_vectorizer.fit_transform(data_frame[\"question\"])\n",
    "len(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **17150** unique words in the corpus.\n",
    "\n",
    "--------------------------\n",
    "\n",
    "### Sample word list in the corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer.get_feature_names()[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document terms matrix is generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search \n",
    "\n",
    "A dictionary is defined with the proposed parameters possible for the model to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defien the params that we want to use\n",
    "search_params = {\"n_components\": [10,12,15,20], \"learning_decay\": [ .5, .7, .9]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LatentDirichletAllocation** function is called on the search parameters defined (plausible hyper-parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the model\n",
    "lda_comparison = LatentDirichletAllocation()\n",
    "# Init Grid Search Class\n",
    "lda_comparison = GridSearchCV(lda_comparison, param_grid=search_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training/fitting\n",
    "\n",
    "Using the fit function, the model will categorise the quora questions in to **n_components** using the learning decay paramters specified before in search array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the grid search\n",
    "lda_comparison.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model\n",
    "\n",
    "The best model is the model which was trained using the hyper-parameters with the highest score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model which gives the highest score\n",
    "best_lda_model = lda_comparison.best_estimator_      \n",
    "# Metrics - log likelihood - higher score = better\n",
    "print(\"Log likelihood : \", best_lda_model.score(doc_term_matrix))\n",
    "# Perplexity - lower = better. \n",
    "# = exp(-1 * log likelihood per word)\n",
    "print(\"Perplexity: \", best_lda_model.perplexity(doc_term_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lda_model.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_comparison.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Words\n",
    "\n",
    "The most occuring 50 words in each Topic is printed. <br> <br>\n",
    "This is used to dervie the Topic names using empherical knowledge of the words most present in the text corpus of each topic cluster identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "probability_list = []\n",
    "\n",
    "top_number = 50\n",
    "topic_count = 0\n",
    "\n",
    "for probability_number in best_lda_model.components_:\n",
    "    text_message = f\"Top words for topic {topic_count} are : \"\n",
    "    print(text_message)\n",
    "    for number in probability_number.argsort()[-top_number:]:\n",
    "        print([count_vectorizer.get_feature_names()[number]], end=\"\")\n",
    "        probability_list.append(number)\n",
    "    print(\"\\n\")\n",
    "    topic_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = best_lda_model.transform(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic selection\n",
    "Based on words, an arbitory topic name is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_desc_list = {0: \"Education\", \n",
    "                   1: \"Research\", \n",
    "                   2: \"Law\", \n",
    "                   3: \"Sport\", \n",
    "                   4: \"Finance\", \n",
    "                   5: \"Health\", \n",
    "                   6: \"horoscopes\", \n",
    "                   7: \"Environment\", \n",
    "                   8: \"Economy\", \n",
    "                   9: \"Various\", \n",
    "                   10: \"Sport\", \n",
    "              }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning the topic number with the highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = []\n",
    "# topics is a list of arrays containing \n",
    "# all index positions of words for each textfile\n",
    "for popular_index_pos in topics:\n",
    "    # Get the max index position in each array\n",
    "    # and add to the topic_list list\n",
    "    topic_list.append(popular_index_pos.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment of topic numbers to the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to the dataframe\n",
    "data_frame[\"Topic number\"] = topic_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using map function the topic descriptions are added to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_no_to_topic_desc = data_frame[\"Topic number\"].map(topic_desc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition the Topic Description column to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame[\"Topic desc\"] = topic_no_to_topic_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample dataframe with question, topic number and topic description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the dataframe to a csv file for the further processing in Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.to_csv(r'quora_supervised.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aim:\n",
    "\n",
    "\n",
    "#### Method:\n",
    "\n",
    "\n",
    "#### Expected output:\n",
    "\n",
    "--------------\n",
    "\n",
    "#### Reading of the text file with the topic classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>Topic number</th>\n",
       "      <th>Topic desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What can make Physics easy to learn?</td>\n",
       "      <td>4</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What was your first sexual experience like?</td>\n",
       "      <td>6</td>\n",
       "      <td>horoscopes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the laws to change your status from a...</td>\n",
       "      <td>2</td>\n",
       "      <td>Law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why are so many Quora users posting questions ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why do rockets look white?</td>\n",
       "      <td>6</td>\n",
       "      <td>horoscopes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  Topic number  Topic desc\n",
       "0               What can make Physics easy to learn?             4     Finance\n",
       "1        What was your first sexual experience like?             6  horoscopes\n",
       "2  What are the laws to change your status from a...             2         Law\n",
       "3  Why are so many Quora users posting questions ...             1    Research\n",
       "4                         Why do rockets look white?             6  horoscopes"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = pd.read_csv(\"quora_supervised.csv\", encoding='utf-8')\n",
    "data_frame.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of Document matrix\n",
    "\n",
    "This creates a sparse matrix which has the occurrence count of each word for each row of the data frame.<br> <br>\n",
    "**CountVectorizer** is used with options: <br> \n",
    "**max_df=0.9** which identify the highly repeated words as stop words and  <br> \n",
    "**min_df=4** which identifies the scarcely occuring words as stop words too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_df is between 0-1 or an INT\n",
    "count_vectorizer = CountVectorizer(max_df=0.90, min_df=4, stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**doc_term_matrix** is the feature list. <br>\n",
    "**target_topic** is the classification expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix = count_vectorizer.fit_transform(data_frame[\"question\"])\n",
    "target_topic = data_frame['Topic number']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test split\n",
    "\n",
    "The current dataset is split into 70% training and 30% for testing the model afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(doc_term_matrix,target_topic, test_size = 0.3, random_state = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier \n",
    "MultinomialNB classifier is created and used to fit/train the model using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnc_classifier = MultinomialNB()\n",
    "mnc_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "The Model is now equipped with data to predict a new review is positive or negative. A **positive review** is fed into the classifier to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnc_model_predictions = mnc_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "In order to evaluate our model for the movie review classifer we are going to use Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4348  195  135  173  168   63  352  132   68   75]\n",
      " [  92 5180  116  195   90  124  213  114   46   71]\n",
      " [ 138  125 3822  198  153   81  288  231  107  107]\n",
      " [  71  129   96 6004  139  125  132  112  102   65]\n",
      " [  89   68   96  217 4548   88  305  117   99   97]\n",
      " [  94  210   88  218   95 3876  444   74   89  107]\n",
      " [  93  197  110   94  128  108 7879   69   78  128]\n",
      " [ 111  141  140  156  171   70  255 5000   79   75]\n",
      " [  80   80  102  159  157   56  262  286 3405   87]\n",
      " [ 107  166  112  132  107   80  447  158   91 3650]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, mnc_model_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification_report\n",
    "Based on the confusion metrics the classification report can be calculated.\n",
    "\n",
    "#### Precision: \n",
    "When it predicts it is of a particular class, how often is it correct?\n",
    "\n",
    "#### Recall\n",
    "Recall is the number of correct results divided by the number of results that should have been returned.\n",
    "\n",
    "#### F1-score\n",
    "The F1 score is the harmonic mean of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall).\n",
    "\n",
    "#### Support\n",
    "The support is the number of occurrences of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.80      5709\n",
      "           1       0.80      0.83      0.81      6241\n",
      "           2       0.79      0.73      0.76      5250\n",
      "           3       0.80      0.86      0.83      6975\n",
      "           4       0.79      0.79      0.79      5724\n",
      "           5       0.83      0.73      0.78      5295\n",
      "           6       0.74      0.89      0.81      8884\n",
      "           7       0.79      0.81      0.80      6198\n",
      "           8       0.82      0.73      0.77      4674\n",
      "           9       0.82      0.72      0.77      5050\n",
      "\n",
      "    accuracy                           0.80     60000\n",
      "   macro avg       0.80      0.79      0.79     60000\n",
      "weighted avg       0.80      0.80      0.79     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, mnc_model_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy                           \n",
    "\n",
    "#### Macro avg\n",
    " \n",
    "#### Weighted avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
